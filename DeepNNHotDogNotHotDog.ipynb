{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "neural-networks-deep-learning",
      "graded_item_id": "TSPse",
      "launcher_item_id": "24mxX"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "name": "DeepNNHotDogNotHotDog.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GqU65x29yWi",
        "colab_type": "text"
      },
      "source": [
        "#HotDog-NotHotDog!\n",
        "This project is inspired by the fictional app Seefood created on HBO's Silicon Valley. The idea of the app is to work as a simple image classifier to identify an image as either a hotdog or not a hotdog. This attempt at classification is built using a 4-layer deep neural network with Relu Activation for the hidden layers and sigmoid for the classification output layer. The model is derived from an exercise in Andrew Ng's Neural Networks and Deep Learning course from deeplearning.ai. The dataset of hotdog images comes from https://www.kaggle.com/dansbecker/hot-dog-not-hot-dog/data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSc14YWlsoQO",
        "colab_type": "text"
      },
      "source": [
        "**Data Pre-processing**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA4xn227uqTv",
        "colab_type": "code",
        "outputId": "504d8dbe-060b-4375-c8c2-d29de26131ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#import my google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#import file navigation libraries\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "#open the zipfile\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/HotDogNotHotDog/hot-dog-not-hot-dog.zip\")\n",
        "zip_ref.extractall(\"/tmp\")\n",
        "zip_ref.close()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWXmps9YTObT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import data-science libraries\n",
        "import numpy as np\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlSZap7LuqT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# store root directories\n",
        "base_dir = '/tmp/seefood'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "#train and test directories\n",
        "train_hotdog_dir = os.path.join(train_dir, 'hot_dog')\n",
        "\n",
        "train_nothotdog_dir = os.path.join(train_dir, 'not_hot_dog')\n",
        "\n",
        "test_hotdog_dir = os.path.join(test_dir, 'hot_dog')\n",
        "\n",
        "test_nothotdog_dir = os.path.join(test_dir, 'not_hot_dog')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO1hK-8_uqT5",
        "colab_type": "code",
        "outputId": "4c0f2b49-dc1b-47c9-961b-819b3963573d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#arrays of fileneames for different datagroups (train_x, train_y, test_x, test_y)\n",
        "train_hotdog_fnames = os.listdir(train_hotdog_dir)\n",
        "train_nothotdog_fnames = os.listdir(train_nothotdog_dir)\n",
        "test_hotdog_fnames = os.listdir(test_hotdog_dir)\n",
        "test_nothotdog_fnames = os.listdir(test_nothotdog_dir)\n",
        "\n",
        "\n",
        "print(train_hotdog_fnames[:10])\n",
        "print(train_nothotdog_fnames[:10])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['3495622.jpg', '1098632.jpg', '116486.jpg', '127117.jpg', '1143044.jpg', '3750744.jpg', '979767.jpg', '3798465.jpg', '910098.jpg', '1344958.jpg']\n",
            "['188505.jpg', '93653.jpg', '98617.jpg', '319830.jpg', '96935.jpg', '274368.jpg', '236973.jpg', '185190.jpg', '89502.jpg', '178804.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWluIU2hvMv3",
        "colab_type": "code",
        "outputId": "9d9d8df6-4910-4643-9614-ebf66083fcb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#show our dataset sizes\n",
        "print('total training hotdog images:', len(os.listdir(train_hotdog_dir)))\n",
        "print('total training nothotdog images:', len(os.listdir(train_nothotdog_dir)))\n",
        "print('total test hotdog images:', len(os.listdir(test_hotdog_dir)))\n",
        "print('total test nothotdog images:', len(os.listdir(test_nothotdog_dir)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training hotdog images: 249\n",
            "total training nothotdog images: 249\n",
            "total test hotdog images: 250\n",
            "total test nothotdog images: 250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2IaZSg9vS0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create arrays with the image represented as resized pixel arrays \n",
        "\n",
        "def fillArrays(filename_set, directory, output_val, img_size):\n",
        "  \"\"\" fillArrays(filename_set, output_val) fills an X data numpy array with images with src filename_set[i] \n",
        "      and a Y numpy array with output_val\n",
        "    Keyword arguments: \n",
        "      filename_set: a python list of filenames\n",
        "      output_val: an integer, 1 or 0, representing the Y value associated with this set\n",
        "      directory: a string representing the filepath for the image set\n",
        "      img_size: the size of the image to standardize to -- image will have dim (img_size, img_size, 3)\n",
        "    Return:\n",
        "      x_array: output array\n",
        "      y_array: output array\n",
        "  \"\"\"\n",
        "  x_array = []\n",
        "  y_array = []\n",
        "  for fname in (filename_set):\n",
        "    img_path = directory + \"/\" + fname\n",
        "    img = cv2.imread(img_path, 3)\n",
        "    b,g,r = cv2.split(img)           # get b, g, r\n",
        "    rgb_img = cv2.merge([r,g,b])\n",
        "    x_array.append(cv2.resize(rgb_img, dsize=(img_size, img_size), interpolation=cv2.INTER_CUBIC))\n",
        "    y_array.append(output_val)\n",
        "  return x_array, y_array\n",
        "\n",
        "first_half_xtrain, first_half_ytrain = fillArrays(train_hotdog_fnames, train_hotdog_dir, 1, 64)\n",
        "second_half_xtrain, second_half_ytrain = fillArrays(train_nothotdog_fnames, train_nothotdog_dir, 0, 64)\n",
        "first_half_xtest, first_half_ytest = fillArrays(test_hotdog_fnames, test_hotdog_dir, 1, 64)\n",
        "second_half_xtest, second_half_ytest = fillArrays(test_nothotdog_fnames, test_nothotdog_dir, 0, 64)\n",
        "\n",
        "train_x_orig = np.array(first_half_xtrain + second_half_xtrain)\n",
        "train_y_orig = np.array(first_half_ytrain + second_half_ytrain)\n",
        "test_x_orig = np.array(first_half_xtest + second_half_xtest)\n",
        "test_y_orig = np.array(first_half_ytest + second_half_ytest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO9Rdj3ZvaB7",
        "colab_type": "code",
        "outputId": "08674831-b42b-4d85-962b-da5e8e2dcbd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "#dataset information\n",
        "m_train = train_x_orig.shape[0] #number of training examples\n",
        "num_px = train_x_orig.shape[1] #number of pixels per image\n",
        "m_test = test_x_orig.shape[0] #number of test examples\n",
        "\n",
        "#reshape Y datasets\n",
        "train_y = train_y_orig.reshape((1, m_train))\n",
        "test_y = test_y_orig.reshape((1, m_test))\n",
        "\n",
        "print (\"Number of training examples: \" + str(m_train))\n",
        "print (\"Number of testing examples: \" + str(m_test))\n",
        "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
        "print (\"train_x_orig shape: \" + str(train_x_orig.shape))\n",
        "print (\"train_y shape: \" + str(train_y.shape))\n",
        "print (\"test_x_orig shape: \" + str(test_x_orig.shape))\n",
        "print (\"test_y shape: \" + str(test_y.shape))\n",
        "\n",
        "plt.imshow(train_x_orig[100])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 498\n",
            "Number of testing examples: 500\n",
            "Each image is of size: (64, 64, 3)\n",
            "train_x_orig shape: (498, 64, 64, 3)\n",
            "train_y shape: (1, 498)\n",
            "test_x_orig shape: (500, 64, 64, 3)\n",
            "test_y shape: (1, 500)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9567d1a860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO19eZhc1XFv1b23957uWTUzGi2jDSSxCRAIZLBZDMYLxgvBW/JwTIyT2O/hOI4x9nv57MR5sRMb23Gc+BFveIkNXsE4rMJgMBgQ+6JdaBlp9rX3vst5f0zPraqDZjQsahH3+X2fPp2eOn369Ln39K06VfUrVEqBgYHBHz6soz0BAwOD+sBsdgODBoHZ7AYGDQKz2Q0MGgRmsxsYNAjMZjcwaBC8rM2OiBch4jZE3ImIn3ylJmVgYPDKA1+qnx0RbQDYDgAXAEAfADwCAO9RSj33yk3PwMDglYLzMt57OgDsVErtBgBAxB8DwCUAMOtmT6VSqrWlFQAAAn9EyBD9sK2Urb2T/yBF6D1WVvQKmKKCKEeIOPRVgyBg/eSPXaVSYTJtEN6VifR+fHz9t9S26bvpwyNarB99T8/35jUPAACLDYoWWw8VwGwolstyHvx9fGxLXpdMtoX6oaYksjny9dEfLnwNgkCX8U+f/Uu/pAeW0l/SH1Qg12pycpR19IVMDMPm4ftyDMRDtwEA3DLdczE2Rt6T1z2VaQrbXtWV49fGKHgeVAJf+4RpvJzN3gMA+9nrPgDYMNcbWlta4ar/+VEAAKjkvi1kljUVtr0gLWQ20AL7QXfYjqTfIvpV/ETYdiJCBJ0dzWG7XCxRP1te9V27d5HMkWuGim0kdsUisZjoVygUw7bny/Gbm+mCWdolicaS1K+lK2wPjcofRr5vHUdewih7nUjQeti+3NAB0iBPbdkqZHaC1j/K9nAy0ST6vf6N72SfK6+Z79H4sUg0bOs/XBZbhGq1KmSRCF1En934liV/WKoVeeMLsB9z/j4+PwAA36d7rFouCdltv/5e2FbepJB57H38R2JyMi/6RaL0PfX5D27fHbaXV+k6/W58XPTbcO7ZYXu4b0jI4lu3AwDA7cMDMBuO+AEdIl6JiJsRcXO+UDjSH2dgYDALXo7NfiYAfEYp9Yba62sAAJRS/zjbe3p6lqq//MtP1waQv5AQsKeQJZ9CiikgZUVtx5K/6D09PWF7uH+fkE2MjoVtiz39ItrjNZagp+vIqPz1tHTdrwZfe83V+EymWcg8l2SVivzxs9i1SKfiYbvqySce2qRJqECq1olUJmzHmMahrIjWj57EqiKfQtUKrX+FPbled97bRT+FNP70EQ6bI2tzlRO1p5piaor+xONPdtdlY2h6sO/SHOPxuJBJk43ex8fT+5VK8v7zfOob+PKp/42vfiJs79j6bNiORROi34KOBWGba1wAAE7fwbDdxD4rmdDM1DxpjGPHrBQyC6bnv+n3D8L41OQh1fiX82R/BABWIeIyRIwCwLsB4OaXMZ6BgcERxEu22ZVSHiJ+BABuBwAbAL6tlHr2MG8zMDA4Sng5B3SglPovAPivV2guBgYGRxAva7O/aKCCwJp2EVgobSuLnQ57IE+3lUc2WcShfi1N0qYZ6NsbtstFaQ/bzE53XbKBA1vasuV8LmzH43J8pehE2Gc2nu4o5Pbf5IQ8UeV2v34CUGX2scvcUJaSNqQTYesRkyfkhTKdTZRz7BwkIc243AS5k3qWLhcyjJA9n1RkQ9pOSvQrs3XUXVIWc8XxtUpongvfpTUNtPMj7orjomQyKfqVFdnR3LWpo1SifoHmXpNnV3IeUeZNcG25ZT768a+F7Wu/+Ckavzoq+lnMFi8FFSFrY1Ph96Pva/3SdD1Tz+8RspHa97Y0j4aYw6wSAwODPyiYzW5g0CCoqxqPABC1plWk/JR0vR3YR/E5bV1tQuZWyOUwOERq6pvedInoNzHJgk+0aK8IU8WqTHUEzd0Tj5OqlIhLtRVYlN84C3jwKlLd4oEjqJkJPnOjBVqACXcNreig8TGxSvQ76ZjesD3W/7SQPXbvL8N2ZsW7aL6+/J7ILv3k0AEhc2xaqzVrjgvbu5+8V/TrXHZ82I4kpcnDjQb+vbxAqvvIXJ+WFhnHA124mj01NSX6Oexa6zLuzpORjVJV5+q/ruLzMbg7cHqO9PrKj/w9vUdNiH7/+k+fphdVee9nomTaBEj3RIulmTz7yEyNa9p6srOl9rmzR0qaJ7uBQYPAbHYDgwaB2ewGBg2CutrslXIRdmx5AgAAbD0JhCUKDB+UNiS3oaIsDFF3XXEXiaeFQ9rsAwOX7LrA01w1Pp0PFHKDQoQ+LdfqnqfC9s6Di0S/1Sup385dMjTyxJPo8xx/p5D9bhuFQC5oIjdRe7f+m0yyJceeICTJ9MKw3f8M2e84Is8HgpVvC9sRR7qysmly500OD4ftpqR081WmKMwz0MNgka4FsKQT3R7mr52IHMP3uH3PMxrlzVNgZya6Te1xG/aQQaS1ebC7KRKLClk6SWc3xWJRyPyA1rU5S+vj+3JNP3bNV8L23139ASFz82TDp2N0v2BSCx9eRPfZWJ8MBw+G+gEAQLmzJwWZJ7uBQYPAbHYDgwZBfSPoAMPIKp00ImBZU9GEnBYLPoJMG2WRpRNSBd+ZI3XIickIvfFRMg0SLEn7+BUyK82xWWbRmFTZ3DLlCuMEtTeslqqTW6AsslZfRlJFpk4J2/3DW4RsfRf5UxavOTNs33vDD0W/E8+8OGzHUmuFbLJIn7d8w2Vh29n6sOiHQz8N289PtQtZ84b30fuSFE2Xy+VEvwRzjY2PPiZkLYtoXrE4U28DTc1kt4GewVepHDrTLaZF4fE8eF3F52457sqLJ6V5xTFXFJ6OdJrWh+fI5/Myk7DCsjU/9YXvCVmqRO7k737kvWG7OyNdv77NMiG1LEa3ZXqN1bDM1OQwT3YDgwaB2ewGBg2C+kbQWRY48Wm1x9E0JU5+oJ+ocl3PjpD6NTEhVeRYnNS7wpSUnXcGqZULuylCb/D5J0S/eJROYkuj8sSz2SYzocgIJMYPyFP77m5SiyeHZSTVgUR/2L7263uE7GtfvzBsb/r1r8J2V49crFhkR9ge7tstZO0L1oXtCjvNXrD8FNEv0k2qtfu4XIODd/wDve+sj4dtJynV51yRVFWdBKQ49DzNt5siABVK9dl16SQ9EZeyMrvuPClGJ56Ismumy2JJkqk5TuM56YWj3ZyFXFHvHsJjxBncs6Dfw03MNNCj91SE1PXLv3db2L7141eKfvYYRdAlm+S1iJ5xxvTc79o061zNk93AoEFgNruBQYPAbHYDgwZBXW12y0JI1ey+wJVpO52dZEdv0aiNx8bJ/s4VyMY77RRp0/T1k+3clpUGWkeabLnxA2TzNjW1iH6TYxQVNtQvCTA6icsR0CY31FOPbhP9IqdSJFwuL7O8tt9DkXfX/vNlQvbgA0Rj3ZJtDdujA/LsoHsBRbXt3indYYuWUOZfeztd3jysE/0SqSXUb4WMrnOCh8L2rvu+GLaXnPMp0c9jVJs6bXyS2b1jfVRKoKlTZvBVqnSdOLkEgKTJLgs+f3nbRjjhgyu/C3e3RaLUL6ZFyZXLnABDjh9PzH4mwMe3uK2vZffxOeqU2fEkvc/zyH5/w5e+K/o9+KNvhO3cTf8pZKXa1w7m4I81T3YDgwaB2ewGBg2Cl8wb/1LQ0tyszj/7tQAAMDw+JmT5PKnMlYpUxbp7KAHg9DMosmz1yiWi38gIubWOaZERTM0ZSkzwbXLx6NFYPEFn6ICsZPXEg78N23GHPuuee6Sbb+Nrya3Vu2a9kOXGSR3VuAkAY6TqZVk1mkpZqurRGKmBnUvXCNnoJLmQKiO0Bp29J8oPq5LJE9Ei1/p2EUmwN0pupycPStV3+VnvD9u2I69ZkvHSc570Ukm6sZq6VoftQLMqOdccV5d5GwAgxlx2+v0cZ+5YLkulZHSax9yUuqouSnZp22U2Qgy9Uo/HKtroyUCCOIOZIfmcJOIosyIrdkSu9x3/8SUAALjx/rthaHL8FeeNNzAw+G8Es9kNDBoEZrMbGDQI6up6i8cSsGrlNEnhG1atEDLOGf6CqpwWC5tkDARRvVRrhUJT03rif5oRIjISismiJP9LsLDJTGu3kK0/vTNs334LhYN++u/PF/28ItmaAxOSiCPG+PEjLT1CloqQjT04QDZk7/KFot/UGGXceUV5NlEaI475SJrmX61Kt5ZfIvs70SZliWY6CykDufJW5XeIfuW9dIZRXXy6kHEb3rJYW/MNlQaJwCPSvFTIcixDLs1q2FU0gs+Auex0W5yfyXBb2dPKIVdZPTrd3uahr7wCsD4mD9vV69aVWVlsnfeezwVZiHBLW6voV2L35pRmz1/04c8AAMDt26XbmuOwT3ZE/DYiDiHiM+xvrYh4JyLuqP3fMtcYBgYGRx/zUeO/CwAXaX/7JABsUkqtAoBNtdcGBgavYhxWjVdK/RYRe7U/XwIA59Ta1wPAPQBw9eHGisVjsHLVdASV70tV3XHod8eLyWnZjJCgxMoJR6KyXzrGM5ekmuZNMeKJZAfNSed1r5JaNjUmM9YSTm/YPudc4nUfHkuLfoUBiqhr6pCqabaJXHYlS7pgSpPkWunqpDmO7JVcdT2ria/93p/+XMiOOYEy56w0fbdA+12PZWjORU01XbCcTJ7cMK2ppbkAB/c/GLZVVrpBJ6s0f1T02ekm6b7jrqbyxF4hi7TQ2imm6nKuQQAAm6nZesZaqUxrytVxX+fQYGak7l6rsBLOumtPlF9mb6xWpamRzdKa6ibEbOOVNHOFOxwTcWkKzJgTOAfR3ks9oOtUSs3ctQMA0DlXZwMDg6OPl30ar6Z/6maNzEHEKxFxMyJuzmlUPQYGBvXDSz2NH0TEbqVUPyJ2A8CsxFdKqesA4DoAgCVLelXRrf0uoIyC8oosssyWvx37+6g01COPPRq2P/TBD4l+viL1To+yKuVJVW1J0mcFSqpK4vcvkIkwLZ20XGMuJe54rlSDK6za63ObHxGyk0+mSLZCn1Rb410UDffIfbeG7QsuulD0K7HKsGtOOU3IolnGvcfUVtSitqJxOt32tcSP0UGKoGtfSNGL+XHpPehkY+597mdCZq35o7BdYaqpXdTKLrETbP3RM36Q5hFfdnLYjsQkyQWnnYtqJmCpRPo6P8XXA0f5qb2uqvPT+RcQT8xS/VWo9wBQKVPUY6Eg7yvOYxfMkcnCP0snx5hJIlKzP3df8pP9ZgC4vNa+HABueonjGBgY1Anzcb39CAAeBIBjEbEPEa8AgM8DwAWIuAMAXl97bWBg8CrGfE7j3zOL6PxZ/m5gYPAqRF0j6PK5Kbj/njsAAGB4REaWHXMM2atdPYuFLJ4it8Wpp20M24Wyxtfu0evtO/qEbO0aIpRAZO4kR46BSLasE5PljngUlN1Ec7rrp78Q/c4+93Vh+4xemfU2sof41Tc/Kef402spQu1v/oSip/bselz0W9S9LGzff7vkg7/0g28P29ueJ3djpvMY0c9i3PZ2s7TFk4rOOyaGw1gq6Fh+lug3yiIWu9ulW+7px26k8dbR86KjbYHo15WleKyq5mrqbCP33cQQrU3PyjNEP9+j97kVSQwRMC73OLP19RJPPBJO57bnnrKI5varsnsuwtx+nMASQBJT8kg7AIBEkvry8lJxzS6PsKi8guYuTdUy//TIPQ4TG29g0CAwm93AoEFQVzU+Fo/DqrXT6vpKJUkXIrzkjqWVf2JetARzkWzZvl30W7OIVF+nIhNtygVK6HASFH2klPy9S2RIrWwKZKRT1KKkmWCKEhHe9j8uF/12Pk087Evae4VsX4Fe56AsZNf/P1KTDzxF6nmgqX17+ogn7w3vkOWfJibIC5ofJ5V2wfKTRD+buZOatEi+0Qpdi4pLJlUmLaO2UstJna5O3SZkx7aQmrlviCIKR1/g1qLP6uiW1XBdxlPYFKc1mBySEYVJZoboxBM8Wq1qkUznkJfVZKUslabkGn18QP4+UscLWrXXikfXOhqXH1AtsvuAV6515L3Jv0syLRN+crX7cS4yGvNkNzBoEJjNbmDQIDCb3cCgQVBXm10pgKo7beNoEZpQYbYz+tJWRhZC6HOuci20MMrKC3uBdONwmnoejRvY0vZxWehrVXNvACv1/MC9lPG1oFN+mYVL6bxA+TJzbuogcb6v6JHlou+5/fdh+4Q1FI7b0SvdZjsep8/evUOu1dTUnrC98kQ6A+h78n7R7/iNVPY5p5GFxDJ09sGz9gq5cdEv2cLIFY57m5BVJq6n+Y9TyPCBeJfoNx6lM5hsi1wPO0bXJvDJyI74Mtw0qNL5iQeSWsG2LdamvyvtPIab8LYtmUADxgFfLctzFkEWyQ6XdNs5w0Jiy2XpHnTYeYTt8uevHCPN7PRKSY6RiEzP2dIJ/BnMk93AoEFgNruBQYOg7mq8502rJjp3NucpQ0Ttfew3iWXLuVUtgo5p7k4sK2Sbn6ZsuXObSdWraKZALKCouahGjjGVI5X8+FNeG7Y3/fLbol81RyrWSRvOFbKOPJVW6lhxnJStpvGnShSRtn+f5H5r7aDvNjyuZfcNkppZ2LclbJcrHaJf4NNi+Z5cx6pHazI0RCWhY5pLdHKI3JltvauFrOW1H6Tx7vtR2E7slmQbxQxlLg4clFGVC5cupxfssz0twg1zxIGf6pamgKdIzebRZfr9x6Pa9PuPl2vSs9lEiSoeYWlLEg0us7R15O48hz1/HY1YhUfXpZPS/JyxQ9B65ckrDAwM/pvBbHYDgwZBXdX4QAWQnyn/o52GxiPsd8eWv0EKSSWyWVmkppSM6LKjTHWS2i30HLMhbE/kiQa6PSvpeousPJHryuQOZKe+Fouc2nDuJaJfKkGyRJOkqh5FGmN5So5/34NPh+2TjyF19OZfPy/6TbqkEi5Y1Ctkp55KauZksT1s79krK82uGKIkmaRGWdzSRKZMnKm3US15JGJT5JoT1eiRm8mT0bOR1se77Tui34E95CUI1kpe01KeSoQlUzTHdEqaaG6V1nHg4G4ha+smT4aIktOi07jqrnPQRR06nde5E3lUG1fd9dN4m6nkupnAiVb4HMtuUevHSkOVpcyryUwEnYGBgdnsBgaNArPZDQwaBHW12UEBWDWbQue39gJ67WlkkQCMM5y5UtLtkghhiLmCVi7rFbJynt7nWIwA0ZMRbq2tZK/u2iF5NBcvoqysg317wnbLIhnh9tA9v6Lx45JP/dRziCDy4Xt/L2S7h+l7n3YBkUy+8XJ5vvG5v/1h2H5qjySt3PQAc914u8L2ZW+SGWWj++4M291LZdbeRIHccmnGL1+tSHvQU6yUlZbBZxfY2rHSTfHlsnR0yzbK7qtOHC9kxRRF73V3HppIEwAAApKp8WEhigPPNiP3Y7kqo/CKRbL7dXKJGCO94G44gBeSVMxAd71ZFr3WM+e4S1Cxe1+37bnbz3XlPTHjijPkFQYGBmazGxg0CuqsxivwQvVDqupcfbFQTgttUqu4+lJ2pUrVwdTFvMbN7VXJVTGiKPooBtIlFc+QWtbeKbnwgiip+HaKqf8ouepOWXdq2N6lJaC4LImjGJMRdA9vIb63R67+ftj+iz9/q+j32X8kTvaPffwnQpawGZ+ZRd957TK5VhYjAXn6ofuEbOWpZ4dtfpUspZF5MJeUfs2sKKmgRVY+qWfdOaJfR5TW8YlnfyVk4xFy2fWz0l6xTEb0S2UpaailrV3IBg/S9W1fQu5BvTxTJELz5zzuAFqEm6OVnmIuNe6G0/tVmPqvmwmixkGERfwpnQOf3JlRzXyYmJx84VgazJPdwKBBYDa7gUGDwGx2A4MGQX2z3kCBW+MkRy0mUXBkaySQPnO9MR4BcDWe8SBK/fqel5zsPT3kdvGYrR80rxT9FAtDrGhnAplYd9iOsnDZ7IJu0W+gOBq2H3hqRMgu3Ei89/958+1CBjYLdS2TPXzdd34nup29oTds/8u175VjKHrfF/6J7Pnv/2RUdLv4HMqI61q8T8iakNyDBwYoZLWtS5afDpi7dHLkoJC5zHbMZFgJ6HF5llJqpnDi3rULhWzbNuLYP8DOIo7NSJJNnxGOWBFpb8cckimW3aeXTeZ2el4rQMrda0ppZbaZHc3dbUWNcNJnYbCW5lIDn8mY60yfB6/vpo8/c+agu+s45lP+aTEi/gYRn0PEZxHxqtrfWxHxTkTcUfu/5XBjGRgYHD3MR433AOCvlVJrAeAMAPgwIq4FgE8CwCal1CoA2FR7bWBg8CrFfGq99QNAf62dQ8QtANADAJcAwDm1btcDwD0AcPVhPzBUM6S6wSOMlKaKWJyDjmlR4xMy+m0hc8EkI9I1YTv02ndJPdrdJ6OZVmRJHU11S0KGXIXe5zMVNs845AEAsm3ksjv++HVCtu8gU5k1CvLJAqmEyFxZE3k5/l13bw7bWzY/IWRsCeCKdxEX3v6dUn3uXEymx5IVMrpu7CBF1w2N99KcIjKzLWBqcWtWusMySRq/WiGVM9Ek3U4Z5/Sw3XzMgJB5RVLxt45SRN7YsCSoyLRQJGWsRV73wKLXiSjjkpMWGuQn6bNSWelK5apxtSojBZNJXoOA7lPOhw8AEAFSwd2yND9jSTLfRPmnuMaFxzjlY1qE3lylnmfwog7oELEXAE4GgIcAoLP2QwAAMAAAnS9mLAMDg/pi3psdEdMA8DMA+KhSSjxq1PRP2iF/WhDxSkTcjIiby+XSoboYGBjUAfPa7IgYgemN/kOl1AyJ2CAidtfk3QAwdKj3KqWuU0qtV0qtj8cTh+piYGBQBxzWZsdpg+VbALBFKXUtE90MAJcDwOdr/980j7FC+0fPCqqyUrvchgGQvN2cycPVph+wjDjflS6Snc8+G7aXrO6lOVmSuO/W26k88sXvlAwueWaupZrIRrUiMkSxWCEbb/GqVUJ29239YbuzV9rK21kJ5ypj8gk0Vp/e42j+a3tl5t/Zp5GNum//1rB9/Gkyo+yYDR8I277TJmRekdxtizvpnCI3IjPKOjrJLo9oNmqRaXEIrGxyXNrsGBDbzf69zwrZmo3kitvxwwfCdmlZr+gXL9McSwVp5wJjNhrpJ0JLJynDapGTUWoZZVxljWgZd/w+5u48ndCSIxaTc+R2Oj8feCHbzaHJMwEACoVi7T2zfuy8/OyvAYA/AYCnEXHmNOhTML3Jb0TEKwBgLwBcNo+xDAwMjhLmcxp/P+hH54TzX9npGBgYHCnUN+sNAJwamaTvaSoK498ONB5zDk6Lzd1fAABNFunZOU2tjDEVCwMmQ6luLT+VyhjtfVpmgy07laLfvCqpqb4n1fgMK5/kdy0XssW95HoreJInXQWcTJNFbWn8+M89uydsdybkOj7zKPU9/91/Sf1WbhT9rCgrR1SS0VhWjFxPyPj37UkZ0WWxKEg92yoWJXWXm2gQyFvOSbOMNevtQgbevWHz4j+h+W95QkYD+kmar1+Uc0wwX2TFo3PlGErTRRBDVKUab7GS1hGNdLOUJ5emFSGZp93DcSbTSzHb7BZMMhM2n5eEpJxvvlzVI+im13uOADoTG29g0Cgwm93AoEFQVzUeQYFVS4TxbZ07myUD6PxdIjKJfp+Gn5Bq9kOPUGTSCW/UEkRYRNr4fjr1zi6SyRcuO1n/5vduE7IvnHxG2K6w0/4mjUyhwiLGpnIycm3ZckommSpINe2S8yguadMD5MnEpIxcsxxSETc/K5NYnHhv2H7bwpPCdlLjx/d9WlONxwFiTBd0GWFFU8cy0a80sTNs21F5Sh1jpkAsyjweSi/ZRSq+H5VemNwQqdqJNEXXRaaeFP3ySKZGkJXqrcuOm3hxVjcl+1UnaV6pJpnmwU++K1rylW2x783u4ahWppiXidLH4GQWkyySL6Z5LooFMlP1E/2ZMQ1vvIGBgdnsBgaNArPZDQwaBPV1vSGGddwckHY55yBH7TfIZq4PmKTyvIs9aQ9nU+ROSse1srjMHhwZJPuvZWGX6Mft1f91zWflGCzSScVp/uPj0hUUQbLjFnbIDKoxRgJ53BpJOLkvRhFqC9vJ9tpxUOYU/PVVVAY6o5EjnnEeRcZVmUvQ1mxIfiziauSIZZvZs2Ue3SVt6lKJ7O24L+eYEhlbzI2ohWwo5k6ytOtuxSl78Mk77grbmais9TZ5kMpAR0+UZzWRCNni8SSdrfgV6aILHJ5JJ92x1SrLNovL8xOfxdcpVostrvXjoSpJrdxykbnvuKxSkRl2PJNOd7HZ9uGf2+bJbmDQIDCb3cCgQVBn1xtCZEadtKSLwGfJHkpJN46vyFUR30KJKk5E4ypn7WdvuVHIshsvCNtRxkGem5IllVccQ6Wchge2Cll1kNxhCxb3hm3blhFXHvNlpVJSZctmya1T0UgM+gJSha96N0Xe/cWX94h+pzKSh2yPLBfN6ds7OyjRxra0BBSmBybS0nXoeaQ+VkvkHkTNbRYNaF5TfTJJxspRtFqkhTjtMN4j+nG+wWhMPnvausj11nXsydQvL82mmDMetidyshxWJX4svWC1BNo188eK0cLp5Zn4NXM9vWQzM2UcMnNe6F4js6Zc1jnruUnL3Hcav3y5TNdlSiNMGRiYvidEtKIG82Q3MGgQmM1uYNAgMJvdwKBBUGfXG4CqhcnqYX0J5sqq+nJaxUeIuKA1Qy6NilbPzWZhjU5FI4FMk7tmqEzv27fredGvrYvIIHwl7bp4E4W6BlWyZVVU2uUYIXs4Epf2cJydPyxoly6kZUvpvKA9Sy7Gs0+QoZEtrIxyrPVkIYsz92MkymxBJbPSeLgsajInQp9nM3ePp9nKxQKVhF7aJm3xrfcT5/vy84izP1+RPqNUisKVA19+Tz9Kc1x0/OvD9n4tGxFccg/md90qRR7dL8tWk6szV5BnNXGPzomaWiWdYpFlBfLsTAAAB9l9W6EzF931VmIlofn6AsiahXxf6AQVJWaz79q1S8j27nm21kfuCQ7zZDcwaBCYzW5g0CCoO3nFrGA+ozaQqohrk5qZYK6suBaNNTlBqtnApFTTHvjOV8L2uZdRlBmUtHJEY/q17J0AACAASURBVEQoEddce+PD5HpLdpGbZXGvjMLr76Mx9Iix0VFyE6VjMoqwqYmi7VoWkDr+4fdJnjlA4k+L2JoLiVtHHrlxqr6MGHNLZOboc/RcMjV4cmK5LEtZRaNkohw88JSQ8ezE0b2UHVeKyCy9dA+tQVCR5lApuoFkFkW4ZXtPEP3Gn6TxW5PS9VSJ071TmaD5J2ypqrsWqdleVWYIJhiRiM7P7jFiEU6Awd1kAADJJI3h+RpxC+e/Y9x1U2OyLsK2bc+F7Wu//L+FrFqZNrHGJuR15jBPdgODBoHZ7AYGDYKjwEE3o7ZJFdZnyS7jD8mqpUlGPFedpBPPZEqW+nFijCtMO8n0C6QSxdiJdSUvVdNt2+l0/tzTVwhZ0EoVXweHttN4/XIMhxELlCsy4qq1m6il0ZUeg45OOu2/bxMxc5/3ZjmPaz5B1V+//D1J6osRUvGDgD7b96R6q7jM1fjM2HqXvHEmkWNYimSRtLwW+w5Q9GFkMUXCxWP6STSZKOMTcoymFlKFW1rodDtmy8iyvoDx5FmSEGTkaSIgSay5OGyvWSar9wrCaN+bVaS0WiguT34RJ+lyCM4srTSaaR7NODZK9+nI0B7R73N//6GwLaPuAIKQOMOQVxgYNDzMZjcwaBCYzW5g0CCob9YbYhgVpPOMTzxKUVFdUSnz8sy+RJK5lpw+lyntm0WZHTreR9FHTlpGsWGVbKH+A4NC1rqU3D9OnFw3qbjM0ssz0ggnJifiBfT76pWlDRxn5xYbzyH3kgXSjfiJj1HUWWn8aSGL2uRKRCAbFT3pCvKKlKXmaPZffpJcWZWJ/fT3CWnL5vbT+ixaLIk7B4q0rmu7yJW195kdot+vt5Jt//b3XCFkyNyKhcqhSSIAANp6qezz73/3iJAlmEvX76W1KU+NiX4BY6MMXHndlU1nCfGUjIzj7rZSiUfQyfMHfr87WhTeyDDNZcfW34ftL37xU3IezB6vamswM37wcggnETGOiA8j4pOI+Cwifrb292WI+BAi7kTEGxAxerixDAwMjh7mo8ZXAOA8pdRJALAOAC5CxDMA4AsA8GWl1EoAGAeAK+YYw8DA4ChjPrXeFADMhOVEav8UAJwHADOEX9cDwGcA4N/nGgsBIIq135eIVGEzHrl/3KpU45GpJgFTZSZzUr312W8X2lKdiUZIdvsvbwjbl175cdGvqmheuwfGhQzSlAjS3EaEBtu3PiO6LV+7LmwXJuUY0SSLznKkGwpHSbXOV+mzRgfl9xzaTxFu6aHvC9nqM4jbfmLfl8O2Zy0V/QKm1mfikj8uN/xo2J6aoM8azUuCiqlxUt3Taan6Bq1kNt19J/HHlcoyOi2eZZFsKM2JVILUeMUrmEYkr5/DLIiLPvBnQrbtvlvCduF5cmdGTjlF9Cu6rHRYWa5HUwclKOm8cNxtFmHc+bm8jGSLM8KUoSG5Vp+6msp0HRzaEraVVt5MJI/JLQJKzfSdvf7TfOuz27UKrkMAcCcA7AKACaXCCgJ9ANAz2/sNDAyOPua12ZVSvlJqHQAsAoDTAWD1fD8AEa9ExM2IuJnXoTYwMKgvXpTrTSk1AQC/AYAzAaAZMTzqXAQAB2Z5z3VKqfVKqfXJpE6va2BgUC8c1mZHxA4AcJVSEzhNHH4BTB/O/QYALgWAHwPA5QBw0+yj1MayLIikpu3U0Tu07swWcjW3XDpC7g2f8cvnS5K4D1lZ3EpV2uwRi2VXsSy6bIe0IYdLLNNI40lvZuV0PVbrbc8BmTnXvZRcKfFks5DFEmS7udq5AiwlO7K5RJl0Y6M7Rbd4mkJ6l63pELL7f04c6ue9fn3YzhX7Rb/d++jSZ1LSRs1kyNVpN1P4abZJ3i5BOyOjtOQZzAUXk/JXzpMtW5yU693UTGcfUxPye6aZLBUnOz1f1K67Q+NbGZkhGI3SnD2LrtPDN8vjpePf9OdhO+JIu7cyQecnmNSJO+l5OTlFdvpMCeUZjOSJJPSDH3iHkPk8y1PRZ+sEL/x1oIXcsl6z/H1+fvZuALgeEW2Y1gRuVErdgojPAcCPEfFzAPA4AHxrHmMZGBgcJcznNP4pADj5EH/fDdP2u4GBwX8D1DWCrjI1Drvu/CUAAMS18ju2x8oya/E5JZ9ljvHMopjsl2dldEpVLcKI8WmfeBaVT7pj0+2i3/rj6HfN8qVquv8guZ7aWVTYqRtfL/qVi3R8kchoqm9AKihqqVEFxknuMD51R+NaX30CRae5he1ClsrSmuwfI5ddc4t0V61YSC7BgYMHhezu39G1Wb+RIvmefEaSKZx+EnGy//53DwpZtp3WatkyMjX0Ut17nqTyyyvPkue+B/ZQpGNLRzdry/WYyvFrLU2vaBOZUdUS9UtM9Il+FRZpF3PlvVOqklmGSnIKRmL88+h91arMdrzqI+8L20Eg3XeSD2N2VZ2r8bOVZp4jgM7ExhsYNArMZjcwaBDUVY13VADt1Wlfu61Xw2QkD1qVIfDYCaXLVSxNDVbst6uikTUcqJJKtLR7Sdh+8uYbRL8LN24M2yPykBomxki9bVtAJ8WFopxwpUy6VLMrPQsBS9bxPammJdjJfSWgk+5kQqq+VWYClUvSHOpaQRFpKkenyPv6pWe0eUFv2B4el3xs+w7QmKN3kZlw6Z9eKPqVxkmt7+mW6nOWEU909JAp8KP/+Lnot2Ih93BI4onuDjITJhlNcz4vST9SSYq0y+XkGJm1ZLK5Yz8K2wmUHpS4RfeVr1VxPbCXkncW9EhTI5enz2vO0jz++E/fLPp5jCxEV8+RRQ5yma6qz0c2m3oPYJ7sBgYNA7PZDQwaBGazGxg0COpqs1uWBcl4LdOrIt0bVY9eu5a0UQOf/SaxLKOpnLS7ApYZNVmQdvRpf0TEjPfc/LOwrTR++R/8v6+F7Yvf8345f8a1nmAlnyKWtMHSC+hMIJ8bELJIjGxPFcjf2liMuYYSzF3lyTFKeXLflcptQjbcTzZ2WzfZvIuPWy76bWFkISMDkst949ksyytC43t56TIqTJAtu+K4XiEbOUB9R9kar1gqzwcWrzkrbOcnZFbd6ACtR6abxs80STfi5CRdF9+T91WxQmcksW6yt+Pjm0W/Up7mqDzNXcpcouMj8lokM+QGfe/ldI/p5CySb167vwNGujKHe42/5tl2/DXOnvRmnuwGBo0Cs9kNDBoE9eWgUwB2TeO1ojJRIBEht9OUlgqLcZrm+AS5ewoayYDFOMlLSqrWP//2d8P2AlaKpyUuCSRaLVKp2ttkksnBPeRmeeop4k5bf865op/vk5rtOO1CFkVSOa2E5CnzRDVVUoOrKOfYsYwSXCZ3PCpkdz5I1VP/7M9oTT1PmjVdS8l12D8oCTZOPJW+967dpLZO9u0R/VLsUXHT96Va/PpLqGLqyF6K0EtY0lXY0kplo/b1SfddUxO5sprjNP/cuFT3m7MUzeh5muuJJ49UieVifJdc+3SZvuegJ68ZMvOwb5/k0PvKN78atn2mjuvuNf5aV8Fn6/diZDMwEXQGBgZmsxsYNArMZjcwaBDU1WZXoMCt2TUJrV6XipJdlHBkZtFQH9l8nBe7JS1dMMNTZM+3xeX4XWlylXnM9ZGOSztRZKWNDwlZIkm2c4W5oTIaoYEPFArsaCQGXp4IGnzN/YgOI1VkIcIVjVxwuECfveL4M4TsHYrmODZFnO9LF8nzjWqK7PK7f/ekkJ39enoGJJI0D6eyRPQbHyGX3YXvPFHIIhZ9b69M6xizJL/8cB8LQc5Koo+yS+6wqSlat2SLtPuH+ul+icWkvZ1gxBYHR6kmX8mS1+y5+38Ztte+4/8I2Z6d9NkPP3q/kHE7fb7QXWoecxdye/6Fdj93y8kx53K5zcA82Q0MGgRmsxsYNAjqqsbbtg3ZWsQRzxYCAHBY5s/EhCRJWLSAVM6AcYpVK5KLLMtcNVXN1TQ1RS6vbDOpi3qk09gEqYi/+dl/Ctnr/vjysD3CyDEeuGuT6HfKOZQdZmlmQkVRxFXCktF7FuPJ81xqp/QxmNpXKMtLqKLkUlu+gFTVoYNPiX7ZLiKA+Pu/O0/IvAqNGY/QfL/5A1lqCoBMo3e8URJgpBMUKbd0Ja33REE+XwKXVHDd5MEcqf//8I/Phu0Pf0yWsO5cuCZsTxXkmsZjNI9YG5kQsefld7Fcuu6To3vlGAlax/Z2aSZ4WsTebOD3mX7PzeYu01Xz+ajqc8E82Q0MGgRmsxsYNAjqqsYHSoXqNWo/MxaLeOvu7hKyAlPXkanPEZTTxwQbtCR1o9YmUheluizV/WyK+hVcmfhRYdTVyQSppuPjUoUdGyHOsq6U9Bg0tdOJdmVQRp1BlOZvsWi6fEmepCdZ5VBlye+ZYVVpgzGKrmvSeM/KOVJV42WpH+7dRafWDzxEFNTvuljyiw6yqq5btksuvJhDavE443s76WSZCLN9C6nqWc1cWbaSknAueSfdE3f/WibuXPLuM8N2c6ekqnZYBdanHyZTJu7I03jHpyjCbFqu6ViZmYua2u7wW44RsOhRcjIRZn6YKxpOx8zHmQg6AwMDs9kNDBoFZrMbGDQI6mqzA1D0UDQqbSaPGRu2JiuPkQ2cYmQB1aK0QxWzmdIJSWhZdoiAssBs4KaMjNYbGKSMKq8qXXs/+9bXw/a7/uLTYTuSzIp+1Ry5+VAjnFQ2LbmfkGWUvSHKWFNRsl8dR7qkKizyLhmTZY7TLfS9/RJl4z380HdEv+NPIXfm6Igko1Q2fd7eUbI9f/P0iOj3lotp/M5lksu9mKfMxb7HaI19R2Y0vuZ8Iq+o5qXbLMG+2nIWyVcakqQlpTK50Ub3SZfaws43hO0u5m70ymnRL1+gMZ/88TeEbN17/y+Nv3hUyFYspjGf2bkHZoNt03NVd71x836+drrjyOs+s6/myoyb95O9Vrb5cUS8pfZ6GSI+hIg7EfEGRK2yg4GBwasKL0aNvwoAtrDXXwCALyulVgLAOABc8UpOzMDA4JXFvNR4RFwEAG8GgH8AgI/htF/hPAB4b63L9QDwGQD490MOUIOFCLEawYSeDFDJk6umUpJqWoZFvFVcUsc9kG6QGCOi0CjZIcbK9Pg+CV0tkSHL1PoR5kIDAMjajLeb8c6lM9Lds50lThR96dpbfeKpYdtypKsp0kpuOa86ydqSA3+SRQNGHElskfXJlTVp07otWXOm6NfcSorYT25/XshOO5PmsXIN9Vu1ULqT7nqIEm1WdEvFLlalCMnv/uq5sD06INXnD36QItJu/YVMyHnjRkquiWdIbV29Un7ncp7cZul2mRikWBGC3lUUaXfbzb8Q/dZ2kUuwWJGloSIsgq61VZpsa5YTz9+zO2kddW1aMdeyroJb1qFVfF0ltxmJxgvM4JpL0PdfPm/8VwDgEwAhe34bAEwopWZ2Wx8A9BzqjQYGBq8OHHazI+JbAGBIKfXo4frO8v4rEXEzIm4uVOcXR2xgYPDKYz5q/GsA4K2I+CYAiANABgC+CgDNiOjUnu6LAODAod6slLoOAK4DAFikhyYZGBjUDfOpz34NAFwDAICI5wDAx5VS70PEnwDApQDwYwC4HABuOtxYQaCgVHN7VbSMtRgji7S0Gm5lFqbqsfDQWFLavMDsFbsi7VyvQm66ZJRCKCfLmhunRP0CzbbymMtu4HkKD+1Yvk70Q0aMsLBdklYGVRrfjkuXmgpY3wrZ7AgaB3mF3FeWLdfKT1BmVyogG7vnmPWi396dvw/b77jsZCFzslSbbd+BO8J2dqEkr3gNK0e9ZdsDQvbIw5QR97krloXtr39rp+h35ZV03tGmhbpu+i250d78rteG7YNj8js/9TC5wxIpSS5x8sazw/aixXRekHTkmlrNFI6bPLBfyCKMtz+ZkvdcnJWgjsXoevramVS1MrtWOxt5Bd8TANKGfyEv/YzsyNR6uxqmD+t2wrQN/62XMZaBgcERxosKqlFK3QMA99TauwHg9Ln6GxgYvHpQdw46v6aSRhPSdcAz0Sr6QR6S+sIrLQVaP+QcXZrbIuLQV+VmQiou+cOLLJLK0lbHY2rxvbf+Kmxf9KeytFI6S9lajz4u3Ulr11JppUXLZASdFaO55CZojpmY5GZLZ8icqBQlCUg6Tll2VUVqpbKk+tnaeXzY3tf3hJA1TZELKdtCY3S3ywy+z3325rD9sb96k5A99jSp4L+6nVxji1ZK06X/wLaw3btafs/OU4h7PojQ2tyzWUbhQYTunUVpeV9lUqS6J9IUXbhqzXGiX8+yVWF7fN82Ibv3x98M2wte98dC1pElc0Uxf2+AUp3m95zudo4z9X8uVZ2r9a6WrTkXF304h8P2MDAw+IOA2ewGBg2CuifCzKgbcU19nhxnvHMas0WEqS8202xcTc2JsiSTkhZ1xj/P5aWhPO1Uln92oJkT7OQ7cEmVdLR+MYfUxSLIE1V+Uj82IEkvmli5qaY2qjhandBCHBgNd6EsVdomjyIAo6zMVWlkSvRzmGmw+pQLhOzmG78Utk8+gdTdA327Rb+N60it//VPHhay1527Nmx7J9BpeWuHJCYZHSLvxJKVi4Tssc0UnX3qyRupvVbeH72rySS57S5pNuWnKAoyWyQPh5OU91+VqcFN3YuFLDZApb5OPP4kIRt4+iHqx+6dijd7sovubeIquSPMTamaV9k9ravtM9F1rjs7tbV5shsYNAjMZjcwaBCYzW5g0CCob8lmRLBqUWmFgoxc4yWcVSB/gxyL7KsKs5VLGhEjMCLGmFYOmUc0+SxiydOy3tIZskNzI5KsweHRah65e357122i3wVvu5TeE5OupnKJ5h+PSuIMh5EgIrPXIkmZYxQA2frJpIw6i8TIFeSwTL+mFs01w/yKqNmQ57zlQ2H7x//2T2H7ksv/SPRbuIRch3fd/pyQfe97FFH37neSuxHsbtGvq4W+i60RfC5fSdGAwwcoGvuGW2X5pzW76bM62hcI2Y6dZG8XS+SmTFjyurS3Ed9+1NJISLO0Vqoi7wmM0vmMYva2rZUMBxb56WhRj7ZF5zrcLtez47hMz3orl6fXTnfriSnMKjEwMPiDgtnsBgYNgqPGQZdIyIgu7irzNFWkWCGVPxEnNXWuqCFXK//EueAUi7iyInIJKkVSs1FLKuCqEx9vfM8zop9vvTdsZ5pbhKzvICVVpJtkRNrIIMnaOolMwU5Kd5UqsKqoWrLExPggva9A46c0Tj4LKLloYkKSdFhMfezsJXfYpz7xfdHvn794ddgOJu4TsresJxW/uZsiCq/6W1kq618+fXHY/v6/3SVkcRaFdvpxNEZHh7zu/fSV4aSTJbnEru20VsUCqf+nn/Y60W/KY6q0L12pkQg9E5/Y9CMhU3G6NgEzCXW3me3MvtW4eh5hJbD00lJz3e8z7rxgjqqy5sluYNAgMJvdwKBBYDa7gUGDoL5Zb0qFdogeLqtYvTGdkIHXM+OkF3qdNpuFy9pa+V9u/aCi8T1XhtVGI2SXp7XaY/2MgDLCPqvgyTGCEoWmViPSVs5kGUlCk7QvS2V6X6VI/PXpZhlGmm6nUNTJIVmKOc7OICIOrWlZC6t184wfX6tDFk+TO2/dBspmO2W9JBzZvo2IKAYGZDjugoVkO97PzHlLi0D+7UNU7+7E02WYanOCbOyDeynk9vSTF4p+TRnql7Dld1m5hNyzJ23YELZ/d58M720bpjVe3Cqz75IJuu6Dw9L11ryKwolX9RJJx9Z9ksTT5QQV2pkUJw2dcaEBSIJJAGmz6+QvM2dhptabgYGB2ewGBo2C+rreEMGuRS4VC2VNhKIfB0/oLzB++URTSvRDpva4ZU3FRxahx8oh6wQBPnO76NFIPCOpxOaE2m/mdV/9fNh+1wf+Ssi8DJEp7NsrOToXdJL6ODZG7sZ4Sq6VbVPkXQCSh31kZE/Y7mLZWxEtSi7P1OnmrIzk85DWpHvhCvZZEslWUq3v/vXNQvbwVpr/liHKlvv4R88V/a79j9+E7UUtMjLu8kuIUGIiR5F2pfKQ6IfMjbhmQ7uQTQzx78YyFaPata0SwUbFkmQkUVa3oLdnlZDtmKSovMWLab2f2ilLWEdZTYOoVs6rWCBTg99jOm+87orjMOQVBgYGIcxmNzBoENQ9gg6c6d+XaEwL5GcUzlYgVRKuaGfaSaXKT8pkmmSa1HpPSZWHJ/XbvNyOK/vxCKSYThvM6Kgn2XwdWy5j2iNZe4tUs6uMvMIFaWrEgJ2+sii28aF+0a+jh06O0+lOIYsrUkcVKz1VVnKObZ1EC2078mS3kiOSB8VUX712Z/9BOtF/y2WvFbIffOfOsH3KKmZ2FCdEv9PWUKTd+a85VsjiNpk5F76ZZBFbqsHDA/vCtq2pyC5LnCoUaD2GBiURx7Nb6bo3RXcI2YnH0VplW+X4iRR5lWLMw5RISS9MlZmVVY3sxOfqOmvPldSiP6aDeZR/NU92A4MGgdnsBgYNArPZDQwaBPXPeqtFa+XHJsXfmxind8mXEWmKRRi5zDSJaXaR5/GsI420kpda4vzyUel6KzMbvjQlo864XRRVLDpN4whPMrvxp9/4kpD98d98js1Xvi8/vitsVxzK8kom5Hcp5Wnt7Kgkr6gAvc9yyT4OPPldBsZYhl2rLFHV1k7utlKVIuMO9g+LfhFGrLntaUle8fa3U7mpUpHOVvr3SXfj6zfQene1yezBpMN49KfIPeXb8uzAZyW19HvCcugcZ2yc8e1LbyYsXMDs7aS0y0dGqRxUz0lyrfKDtMbcZq9qhKcBu+d0lxoHt9PntNlBd7Ud3mafb332PQCQg+mzMk8ptR4RWwHgBgDoBYA9AHCZUux0yMDA4FWFF6PGn6uUWqeUmvnJ/iQAbFJKrQKATbXXBgYGr1K8HDX+EgA4p9a+HqZrwF09W2eAadU6WSOt8LVooCJLAIinZUTX5DglIqSTrNyOlgiTZIQYE0W9RNBss5IqFbJSU56mblnMxeZY5K6KuLJflUXopXwZFTY6SqpwS1ubkLkWuRXTaXLZ6Qrb2BBFrnUslFGEVorccm6R1m1qQrq8Uoxrr39gl5DlSrSuqSzNKZWW0WnP73gkbEds6QLcv5vcYccsp89yFshvw8tt5Ydl4ofv0PcMkHj47rxbus3OPYd47Q48PyhkRbYGvkP3x7hWCXblCkpoyWgu18lhGtNCmcDlFmhduRtX19S56j5XtNt8IuEA4AVau10rn6ZzKnLM98muAOAORHwUEa+s/a1TKTXjAB4AgM5Dv9XAwODVgPk+2c9SSh1AxAUAcCcibuVCpZRCxEOeENR+HK4EAMgmYofqYmBgUAfM68mulDpQ+38IAH4B06WaBxGxGwCg9v/QLO+9Tim1Xim1PhWdVZc2MDA4wjjskx0RUwBgKaVytfaFAPB3AHAzAFwOAJ+v/X/T4cYKfB/ytay1F9SqYsSJVc0WT7O6XAkWRupqvx088T+elC6YSolsQ87JrteL07PgOBxmPcd5WKbGEe5w0kBtvE3Xfy1sv+0jnxKynM2+J7PxIil5hlEskC07NSpt1LZFZNtW7ZU0p/EHRD+3TNlanKwCAMBn4b6ItN7RqLxmPYtoXvmmNUL2/H/ROUB3O62BV5YOG8snN1qpIMtPty8nN9dttxIZxEVvWCL6VRhZyJat8mxi5QoiCxnNkfJZ0rIiJw6SS9DKyrODtjY6B6mmJMFGuULlrvcP0/OOZ1YCyPtdd71x2dzutkO/h48519vno8Z3AsAvaoM7APCfSqnbEPERALgREa8AgL0AcNm8ZmlgYHBUcNjNrpTaDQAnHeLvowBw/pGYlIGBwSuPupd/itSS83V1Q7GINFdTi/MT5L6yM6Q6RjSOLv51ckWpEqLDMt2qTMXy5URizH3na5PMF8idZzOVvlrReOxi3EUnZ+i7ZE4EBalyRrKUAVbIk2svKi0SSDK++dEheVRiMV799jZykEylZORXlq2j0rL2ihNkJuRHSB13benm61xALq9ITGb3nXT6aWG7fy9FxvV2SxX8wCCZIceulCry0BiZQwGSy/LaL+0T/f78w/Q9OxfK7+lXyXW4d2df2H7rJWtFv023Ep/exLhcj9Ur3xq2U3otgTSZCQ88+MuwbTuamo3c9aYflR1a91ZzBMkF2h6xDXmFgYHBDMxmNzBoEJjNbmDQIKirzR4EAZRrGVA6eZ7HbBBHYyLh5o/FXBpKyd8q4cLQPjvBShTzAVWLDH8s5simjmq2bJKVQK5wvnmU9lOMufZ0MkpkvO63f/ffhOySv/oMzZeRHOo8+sBCNlGrIRawungDg7TGHT0nin75YcpSy+Ul53u6iezveJxKIKc1DvxKlc4VlJJnJEmWOdY/Suvj+3tEv8WdvWF7dFDWnBsski2+p48+q2ul5HXfPUDzam2RLrU9+4jnvfc4stNzOTnfEcbAuWq9PHf2s+TODLQzngILkW3JsnLZEWlDcxevW5X3C3fFuczt7GisOw47o4olZOafqmV8jk1I9iYO82Q3MGgQmM1uYNAgqKsab1kIsdi0apJulq6a/CQRC0QiUrVORUl94ap61ZNRSqUCqXpxS8bhI+tbLtNnJeKyBBO3DNyKVAl9Zmp4zFBoycjSyxE2LZ0I0GfzSKKcvztKhBL7poigoliQ2XFd3aTexhPys0tFin6LpkgNxJgcw0eKmtuzV6Q6wIJmWoQO5iqLJ6T6GY+R2hokpFuuEKfre8ZrzwjbO578veiX6aCS1tt3SNXaZlbDVIlMqNEh6bLcOUyvF2Wk6rt2DbkHvUlS/ycGZSTfJe95Q9iuJk8Qshgr1f3II48L2a9uuTFsZ9J0304VpTs2yQhWNe4N4PyqI8zNnG6SZhP3tuXyUl2fMQX8OYgxzJPdwKBBYDa7gUGDoO5VXN3aabqfl+QSKVbKKa/JimU68eRVVlGrPhpjKnMxL0kjsi0UMZaOkupbLEnOOZSZagAADWZJREFUdK/C+OUdaQqUWcSbw6KgXM2csFgijO9pBBts/r7GbX/3D78Rts9874foc4uaOsdMCLeqNBmpcSlW0bSQl6RrrYuOCdvHOdKkqlRYmaQUW9Oc5KBL+7R2TTF5+jwe0BgjrNTXohVSRb7/XiLAGC5Jk2rFclqf4WEyvSytQq8KaI2XnfgaIUPGSZcvs+Si5hWiX2wBRfyVclIF5/efY8vr2bOAzKGAmZj9ozLKr1Sh+6UlI79nlZmLrk9zHBuXPI0eI0mxI1ql49plmiuNxjzZDQwaBGazGxg0CMxmNzBoENS/1lvNuChpvNous79dzRZPxMnOrRbJTsxNysiv9iy5cdJpaee6LDMtniCZ7cjP8pj9l9OikbJs/GKBfbbmXktHmQtGixSMMlvL12qn2SzK6rH/+kXYPvWt7xP99u+j7K1kQmb+ZRhRZYFFA+Y1mz2a6KUXWu0xFgAIrktzzLTLWmwDA1SDLqakfXlwmEosV3y6zQoT8jxGMRKJA/0yg+/JHXSt33rp6WG7vfd00e/AQXJZBtr5SZHZuYpVDTxz40bRb4K5shYuWSZkAwPkpvveD34g58/dsQEv9y26QZVF2g2PS7dfwOoHBMHsVjd3O9taxqc3k8k5//JwBgYGf6gwm93AoEFQ50QYBaWaOhmJzE4+mdT440YGSb3r5oQJIFWZWJKirMYGJTcb52EfHiYXUkT7LJ6UkM1KFwnnp+P9WjPSdRVniSt2UnKQ2ywaUGnln8qsrDSMECdazNWSG1xyCRZ8+XvN+eG7uyhqrqqReUyOUtJJNCE56CJFWh8eAZjX3JkJlqhRLstIvo617w7bw4M0XmqhXNPMsWReLNHKZ5eZqeez5JFcTpoC3V3EEde3v0/IeMJV7zHEyTeRly60skvrWKpIN+K//guV8PI0VypXpzkphcYtAQ6zjVQweyLMXLzxvKSZq/E0RiPT94SvlU4T759VYmBg8AcFs9kNDBoEZrMbGDQIcL481a8EutIJdfm6abeGbpsMDhPJQEurZkMy25DbKpavcc8zEkgrolWfYXa0Yu4ZzeSFPMuICzRu8UqRu+/IJZWIaeGbbAxbYw2MscyokkZUWa2QfVmpkNtp0pFZgOe+/8M0f+332nXpszmBRDYl1yNg5x3dvcuFrDjG7F6keQSaTc058Tm/PADA2CSdEcSidKbRPyzPUng9vYJWn4+Hh3q85LHmXptkRBSBVuusvWth2G7K0rmCQnlc5bDSznmN2OJfv/5FmA3cjuZ11vR9xe93vZw4B89aU9q9w+99fXynVuvNdT0IghdQVU5/7qyfamBg8AcFs9kNDBoEdVXjFySj6p0rpznNuCsMAEDZpHkkYxovHONrjzIiAV2dizPV3Q2kJlNifGkOYw+oamofLwtULZSErCXNy0WTCm5Z8rMS/OULNCrGx6YtfZ65mlymzukc4aNA7rzX/Y8PCplfoTnH49TPjsnf9SQr5VTR1PNkM5lRKYfmZKPs5zK3lufJOeYYiQZ3dRYK0nTxmXqeL8r1Vuwauuw6FcuyX3sHkXksWX6MkOVy5IpMpOh7jY1LAoy2duLa+9q/fEHIBgZYaShNBeevq8wtp5d44tDdzvz6WhZ35UnTiO9VfR7V8vT9/bLVeERsRsSfIuJWRNyCiGciYisi3omIO2r/txx+JAMDg6OF+arxXwWA25RSq2G6FNQWAPgkAGxSSq0CgE211wYGBq9SzKeKaxYAXgsA7wcAUEpVAaCKiJcAwDm1btcDwD0AcPVcY1mWBalagkpUO8H2vNnVYv46HmdJLFpJ+HyO1DtfU4Fsh1T33BRFpDkaFXOEndqjNo+gRKppU4JHxklTIMFKU+scdPxUtqKZITyWL89O4zEmT9LTjPo54coElwlGomex6C69RBWw03gbdC4/VuaKlYmKBjKSz2ffxfXkPHjiUcXjqq5GxczIQ3T+NH4Cn21tD9spSyYQTebpuj+3Y7eQLV1MNNDjjAzCdeU8du/eErbHxiRJRxMrt6VHEXLwaDoFemky5gHSvicv3eSxE3c9SYuPP6O2z2A+VVzn82RfBgDDAPAdRHwcEb9ZK93cqZSaSXsagOlqrwYGBq9SzGezOwBwCgD8u1LqZAAogKayq+mTg0P+piDilYi4GRE3F13/UF0MDAzqgPls9j4A6FNKPVR7/VOY3vyDiNgNAFD7f+hQb1ZKXaeUWq+UWp+M6KqNgYFBvTCf+uwDiLgfEY9VSm2D6Zrsz9X+XQ4An6/9f9OL+WDd5VdhpHsI0h7JsMgni9k3UxOSvKLCiAF1mx2ZSyMeJ9deUYvaivOzBG2OEVZ/2WI2WCwuM9ss5l6LaGcCIltJc1dVmZ3O51jRiD4sFv119/VfFzK/lWzU17z90rCNWqksPkZJixRMIIvUCpi9bcuMtb7nqZxzoJ2f8Ai6gJEoRlOSvz6dYJFxmm7IyUDHCzxaT67H6ATZ4htPO0UOYtH1nGLHCrxUEwDAdZ/7ZxpfO6spFGY/45H3EuunPde4Da+XPuNj8DJROrjNHo3Je8epkaPmpqRbUvSZVSLxPwHgh4gYBYDdAPCnMK0V3IiIVwDAXgC4bJ5jGRgYHAXMa7MrpZ4AgPWHEJ1/iL8ZGBi8ClFX8gpEhFitDA5P9AAAcKuk2kQ0l0P/QUqeaGmh2B2lVTfFKH0dy5JfrcLdSaw6ayIp3Voud681ySi/KDuDRB7+5kuVivOaOxGt2iZ3u9ha5B0j0vBYhJStjR+xaa1Kmgup3L8nbN/wb18J25de+ReiX6FCYzZlZFXU/Nho2M5ViUuuk5FEAAAgq2o7cmCvnCPj4cszN1zZlWaTw8oiTU1Js6zKzByXRac5mpqdYuaVq7m1nnuGXGrJJnIjlqeke43HnNma+RZl6nNZI43gKnl7K5k5I2MyQs9m6r8dlfdENHJoV62N8v4OfLo39Tm61em+c0XEmth4A4MGgdnsBgYNArPZDQwaBHXnjfdr4ZLxmCR6TMTJFVLS6q/xDDlu66Nms3O3iLJlOK7PCDBQsbLJCWk/WRmal6+HmJZYzTmefae5SxSbh6dlrCEnKIzI5Vc+cx2yLD0VlX6cgC1PJK7Zfzx7kLkzf/nd/xD93v5+ypZzWuQYTpKuxVSOwkO1BEFoaqVMsZ1bnxayZIK+C7LstdKUJK+ocgISW7sdWYizl2fZa1pNgONO3UCyNhnI2TZC7rBlS7vC9mf+99+Ifq1ZGnNsXDs7YAZ9XD+DYTYyd9FxdxqAdLnGtPDn2bLZEOTZhGL8+3pem1+7OKbWm4GBgdnsBgaNgrqSVyDiMEwH4LQDwMhhuh9pvBrmAGDmocPMQ+LFzmOpUqrjUIK6bvbwQxE3K6UOFaTTUHMw8zDzqOc8jBpvYNAgMJvdwKBBcLQ2+3VH6XM5Xg1zADDz0GHmIfGKzeOo2OwGBgb1h1HjDQwaBHXd7Ih4ESJuQ8SdiFg3NlpE/DYiDiHiM+xvdafCRsTFiPgbRHwOEZ9FxKuOxlwQMY6IDyPik7V5fLb292WI+FDt+txQ4y844kBEu8ZveMvRmgci7kHEpxHxCUTcXPvb0bhHjhhte902O04z3n8dAN4IAGsB4D2IuLZOH/9dALhI+9vRoML2AOCvlVJrAeAMAPhwbQ3qPZcKAJynlDoJANYBwEWIeAYAfAEAvqyUWgkA4wBwxRGexwyugml68hkcrXmcq5Rax1xdR+MeOXK07UqpuvwDgDMB4Hb2+hoAuKaOn98LAM+w19sAoLvW7gaAbfWaC5vDTQBwwdGcC0wzWD8GABtgOnjDOdT1OoKfv6h2A58HALcAAB6leewBgHbtb3W9LgCQBYDnoXaW9krPo55qfA8A7Gev+2p/O1o4qlTYiNgLACcDwENHYy411fkJmCYKvRMAdgHAhFJqJoOlXtfnKwDwCaC6WG1HaR4KAO5AxEcR8cra3+p9XY4obbs5oIO5qbCPBBAxDQA/A4CPKqVEilW95qKU8pVS62D6yXo6AKw+0p+pAxHfAgBDSqlH6/3Zh8BZSqlTYNrM/DAivpYL63RdXhZt++FQz81+AAAWs9eLan87WpgXFfYrDUSMwPRG/6FS6udHcy4AAEqpCQD4DUyry82IIe1sPa7PawDgrYi4BwB+DNOq/FePwjxAKXWg9v8QAPwCpn8A631dXhZt++FQz83+CACsqp20RgHg3QBwcx0/X8fNME2BDfASqLBfCnC69tO3AGCLUuraozUXROxAxOZaOwHT5wZbYHrTz/BPH/F5KKWuUUotUkr1wvT9cLdS6n31ngciphCxaaYNABcCwDNQ5+uilBoAgP2IeGztTzO07a/MPI70wYd20PAmANgO0/bhp+v4uT8CgH4AcGH61/MKmLYNNwHADgC4CwBa6zCPs2BaBXsKAJ6o/XtTvecCACcCwOO1eTwDAH9b+/tyAHgYAHYCwE8AIFbHa3QOANxyNOZR+7wna/+enbk3j9I9sg4ANteuzS8BoOWVmoeJoDMwaBCYAzoDgwaB2ewGBg0Cs9kNDBoEZrMbGDQIzGY3MGgQmM1uYNAgMJvdwKBBYDa7gUGD4P8DqBdRnvElvTAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtDdRVv4uqT8",
        "colab_type": "code",
        "outputId": "b53663ca-1fa4-4c59-80f0-a76430b22253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Reshape the training and test examples \n",
        "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\n",
        "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n",
        "\n",
        "# Standardize data to have feature values between 0 and 1.\n",
        "train_x = train_x_flatten/255.\n",
        "test_x = test_x_flatten/255.\n",
        "\n",
        "print (\"train_x's shape: \" + str(train_x.shape))\n",
        "print (\"test_x's shape: \" + str(test_x.shape))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_x's shape: (12288, 498)\n",
            "test_x's shape: (12288, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90o2knAiCerW",
        "colab_type": "text"
      },
      "source": [
        "**Model Constants**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlxNn1-NuqUB",
        "colab_type": "code",
        "outputId": "acf1e1f7-8ec8-43e4-b1c6-4795d9742a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n_x = train_x.shape[0]     # num_px * num_px * 3\n",
        "n_y = 1 # number of units in the output layer\n",
        "layers_dims = [n_x, 20, 7, 5, n_y] #units in each layer\n",
        "print(layers_dims)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[12288, 20, 7, 5, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs8Wh2jGCkfr",
        "colab_type": "text"
      },
      "source": [
        "**Activation Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IabDhi_ayWjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(Z):\n",
        "    \"\"\"\n",
        "    sigmoid activation in numpy\n",
        "    inputs:\n",
        "      Z: numpy array\n",
        "    outputs:\n",
        "      A: output of sigmoid(z), same shape as Z\n",
        "      cache: hold Z to be used for backpropagation\n",
        "    \"\"\"\n",
        "    A = 1/(1+np.exp(-Z))\n",
        "    cache = Z\n",
        "    return A, cache\n",
        "\n",
        "def relu(Z):\n",
        "    \"\"\"\n",
        "    RELU function.\n",
        "    inputs:\n",
        "      Z: output of of the linear activation\n",
        "    outputs:\n",
        "      A: relu(Z)\n",
        "      cache: Z\n",
        "    \"\"\"\n",
        "    A = np.maximum(0,Z)    \n",
        "    cache = Z \n",
        "    return A, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV1KWxObD4Fd",
        "colab_type": "text"
      },
      "source": [
        "**Cost-Gradient Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0NZAXxkyYHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu_backward(dA, cache):\n",
        "    \"\"\"\n",
        "    backward propagation for a single RELU unit.\n",
        "    inputs:\n",
        "      dA: post-activation gradient, of any shape\n",
        "      cache: 'Z' from forward propagation at this step\n",
        "    outputs:\n",
        "      dZ: gradient of the cost with respect to Z\n",
        "    \"\"\"\n",
        "    Z = cache\n",
        "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
        "    dZ[Z <= 0] = 0    \n",
        "    return dZ\n",
        "\n",
        "def sigmoid_backward(dA, cache):\n",
        "    \"\"\"\n",
        "    backward propagation for a single SIGMOID unit.\n",
        "    inputs:\n",
        "      dA: post-activation gradient, of any shape\n",
        "      cache: 'Z' from forward propagation at this step\n",
        "    outputs:\n",
        "      dZ: gradient of the cost with respect to Z\n",
        "    \"\"\"\n",
        "    Z = cache\n",
        "    s = 1/(1+np.exp(-Z))\n",
        "    dZ = dA * s * (1-s)    \n",
        "    return dZ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21zOjTbDERZB",
        "colab_type": "text"
      },
      "source": [
        "**Parameter Initialization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cC7EqBRye-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_parameters(layer_dims):\n",
        "    \"\"\"\n",
        "    inputs:\n",
        "      layer_dims: list containing the dimensions of each layer in our network\n",
        "    outputs:\n",
        "      parameters: python dictionary containing your parameters Wi, Bi for 1<i<=L:\n",
        "          Wi: weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
        "          bi: bias vector of shape (layer_dims[l], 1)\n",
        "    \"\"\"\n",
        "    \n",
        "    np.random.seed(5)\n",
        "    parameters = {}\n",
        "    L = len(layer_dims)\n",
        "\n",
        "    #initialize parameters\n",
        "    for l in range(1, L):\n",
        "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1])*0.25\n",
        "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))    \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki4jKn21FH6C",
        "colab_type": "text"
      },
      "source": [
        "**Forward Propagation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASDWRCwxyjMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_forward(A, W, b):\n",
        "    \"\"\"\n",
        "    calculates Z = W.T*X + b for one step of forward propagation\n",
        "    inputs:\n",
        "      A: activations from previous layer, shape = (size of previous layer, number of examples)\n",
        "      W: weights matrix, shape = (size of current layer, size of previous layer)\n",
        "      b: bias vector, shape = (size of the current layer, 1)\n",
        "    outputs:\n",
        "      Z: the linear activation function matrix \n",
        "      cache: dictionary to store the input values at this step for back propagation\n",
        "    \"\"\"\n",
        "    Z = np.dot(W, A) + b\n",
        "    cache = (A, W, b)\n",
        "    return Z, cache\n",
        "\n",
        "def linear_activation_forward(A_prev, W, b, activation):\n",
        "    \"\"\"\n",
        "    forward propagation for the LINEAR->ACTIVATION layer\n",
        "    inputs:\n",
        "      A_prev: activations from previous layer, shape = (size of previous layer, number of examples)\n",
        "      W: weights matrix, shape = (size of current layer, size of previous layer)\n",
        "      b: bias vector, shape = (size of the current layer, 1)\n",
        "      activation: the type of activation function applied to this layer\n",
        "    outputs:\n",
        "      A: the output of the activation function\n",
        "      cache: a python dictionary containing \"linear_cache\" and \"activation_cache\";\n",
        "             stored for computing the backward pass efficiently\n",
        "    \"\"\"\n",
        "    if activation == \"sigmoid\":\n",
        "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
        "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "        A, activation_cache = sigmoid(Z)\n",
        "    elif activation == \"relu\":\n",
        "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
        "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "        A, activation_cache = relu(Z)\n",
        "    cache = (linear_cache, activation_cache)\n",
        "    return A, cache\n",
        "\n",
        "def forward_propagation(X, parameters):\n",
        "    \"\"\"\n",
        "    forward propagation for all of the layers\n",
        "    inputs:\n",
        "      X: train data, shape = (input size, number of examples)\n",
        "      parameters: output of initialize_parameters()\n",
        "    outputs:\n",
        "      AL: last post-activation value\n",
        "      caches: list of caches containing the activation values\n",
        "    \"\"\"\n",
        "    caches = []\n",
        "    A = X\n",
        "    L = len(parameters) // 2                  # number of layers in the neural network\n",
        "    \n",
        "    #relu activation layers\n",
        "    for l in range(1, L):\n",
        "        A_prev = A \n",
        "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation = \"relu\")\n",
        "        caches.append(cache)\n",
        "    \n",
        "    #sigmoid activation layers\n",
        "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], activation = \"sigmoid\")\n",
        "    caches.append(cache)\n",
        "            \n",
        "    return AL, caches\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoJ8dc3PHFQf",
        "colab_type": "text"
      },
      "source": [
        "**Cost of Forward Propagation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBuEqCa5yneC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cost_function(AL, Y):\n",
        "    \"\"\"\n",
        "    cross-entropy cost function\n",
        "    inputs:\n",
        "      AL -- estimate of forward propagation, shape = (1, number of examples)\n",
        "      Y -- actual classification (1 for hotdog, 0 for nothotdog), shape = (1, number of examples)\n",
        "    outputs:\n",
        "      cost -- cross-entropy cost\n",
        "    \"\"\"\n",
        "    m = Y.shape[1]\n",
        "    cost = (1./m) * (-np.dot(Y,np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T))\n",
        "    cost = np.squeeze(cost)          \n",
        "    return cost\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YdowXlvHfxB",
        "colab_type": "text"
      },
      "source": [
        "**Back Propagation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyIkLN5cyp4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_backward(dZ, cache):\n",
        "    \"\"\"\n",
        "    linear \"deactivation\" for backward propagation for one layer\n",
        "    inputs:\n",
        "      dZ: gradient of the cost with respect to the linear output (of current layer l)\n",
        "      cache: tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
        "    Returns:\n",
        "      dA_prev: gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
        "      dW: gradient of the cost with respect to W (current layer l), same shape as W\n",
        "      db: gradient of the cost with respect to b (current layer l), same shape as b\n",
        "    \"\"\"\n",
        "    A_prev, W, b = cache\n",
        "    m = A_prev.shape[1]\n",
        "\n",
        "    dW = 1./m * np.dot(dZ,A_prev.T)\n",
        "    db = 1./m * np.sum(dZ, axis = 1, keepdims = True)\n",
        "    dA_prev = np.dot(W.T,dZ)\n",
        "\n",
        "    return dA_prev, dW, db\n",
        "\n",
        "def linear_activation_backward(dA, cache, activation):\n",
        "    \"\"\"\n",
        "    backward propagation for the LINEAR->ACTIVATION layer.\n",
        "    inputs:\n",
        "      dA: post-activation gradient for current layer l \n",
        "      cache: tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
        "      activation: the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
        "    outputs:\n",
        "      A_prev: Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
        "      dW: Gradient of the cost with respect to W (current layer l), same shape as W\n",
        "      db: Gradient of the cost with respect to b (current layer l), same shape as b\n",
        "    \"\"\"\n",
        "    linear_cache, activation_cache = cache\n",
        "    \n",
        "    if activation == \"relu\":\n",
        "        dZ = relu_backward(dA, activation_cache)\n",
        "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
        "        \n",
        "    elif activation == \"sigmoid\":\n",
        "        dZ = sigmoid_backward(dA, activation_cache)\n",
        "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
        "    \n",
        "    return dA_prev, dW, db\n",
        "\n",
        "def backward_propagation(AL, Y, caches):\n",
        "    \"\"\"\n",
        "    backward propagation for all layers\n",
        "    inputs:\n",
        "      AL: output of the forward propagation\n",
        "      Y: actual classification (1 for hotdog, 0 for nothotdog), shape = (1, number of examples)\n",
        "      caches: list of caches containing activation caches\n",
        "    Returns:\n",
        "      grads: A dictionary with the gradients dA, dW, dB \n",
        "    \"\"\"\n",
        "    grads = {}\n",
        "    L = len(caches) # the number of layers\n",
        "    m = AL.shape[1]\n",
        "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
        "    \n",
        "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
        "    \n",
        "    current_cache = caches[L-1]\n",
        "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = \"sigmoid\")\n",
        "    \n",
        "    for l in reversed(range(L-1)):\n",
        "        current_cache = caches[l]\n",
        "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, activation = \"relu\")\n",
        "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
        "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
        "        grads[\"db\" + str(l + 1)] = db_temp\n",
        "\n",
        "    return grads\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSK_pUgd1PVg",
        "colab_type": "text"
      },
      "source": [
        "**Update Parameters after Back Propagation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJHo1jYdyuDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_parameters(parameters, grads, learning_rate):\n",
        "    \"\"\"\n",
        "    Update parameters with gradient descent\n",
        "    Arguments:\n",
        "      parameters: python dictionary containing parameters \n",
        "      grads: python dictionary containing gradients, output of L_model_backward\n",
        "      learning_rate: how much of a \"step\" do we take each iteration of gradient descent\n",
        "    Returns:\n",
        "      parameters: python dictionary containing the updated W and b\n",
        "    \"\"\"\n",
        "    L = len(parameters) // 2 # number of layers in the neural network\n",
        "    \n",
        "    # Update each parameter\n",
        "    for l in range(L):\n",
        "        parameters[\"W\" + str(l+1)] = parameters.get(\"W\" + str(l+1)) - learning_rate*grads.get(\"dW\" + str(l+1))\n",
        "        parameters[\"b\" + str(l+1)] = parameters.get(\"b\" + str(l+1)) - learning_rate*grads.get(\"db\" + str(l+1))\n",
        "        \n",
        "    return parameters\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dERcyktm1WgI",
        "colab_type": "text"
      },
      "source": [
        "**Predictor Function**:\n",
        "Uses the parameters obtained by the model to make a prediction for the output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmcsolbHywvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(X, y, parameters):\n",
        "    \"\"\"\n",
        "    This function is used to predict the results of the neural network.\n",
        "    Arguments:\n",
        "      X: data set of examples you would like to label\n",
        "      y: the label of the corresponding X\n",
        "      parameters: parameters of the trained model\n",
        "    Returns:\n",
        "      p: predictions for the given dataset X\n",
        "    \"\"\"\n",
        "    m = X.shape[1]\n",
        "    n = len(parameters) // 2 # number of layers in the neural network\n",
        "    p = np.zeros((1,m))\n",
        "    \n",
        "    # Forward propagation\n",
        "    probas, caches = forward_propagation(X, parameters)\n",
        "    \n",
        "    # convert probas to 0/1 predictions\n",
        "    for i in range(0, probas.shape[1]):\n",
        "        if probas[0,i] > 0.5:\n",
        "            p[0,i] = 1\n",
        "        else:\n",
        "            p[0,i] = 0\n",
        "    \n",
        "    #print accuracy\n",
        "    print(\"Accuracy: \"  + str(np.sum((p == y)/m)))   \n",
        "    return p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reX0emgA1qup",
        "colab_type": "text"
      },
      "source": [
        "**Model using above helper functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9mkQKYfuqUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 2500, print_cost=False):\n",
        "    \"\"\"\n",
        "    the neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
        "    inputs:\n",
        "      X: data, numpy array of shape (num_px * num_px * 3, number of examples)\n",
        "      Y: output vector, (1 if hotdog, 0 if nothotdog)\n",
        "      layers_dims: list containing the input size and each layer size, of length (number of layers + 1).\n",
        "      learning_rate: learning rate of the gradient descent update rule\n",
        "      num_iterations: number of iterations of the optimization loop\n",
        "      print_cost: if True, it prints the cost every 100 steps\n",
        "    outputs:\n",
        "      parameters: parameters learnt by the model. They can then be used to predict.\n",
        "    \"\"\"\n",
        "    np.random.seed(1)\n",
        "    costs = []                         # keep track of cost\n",
        "    \n",
        "    # Parameters initialization\n",
        "    parameters = initialize_parameters(layers_dims)\n",
        "    \n",
        "    # Loop (gradient descent)\n",
        "    for i in range(0, num_iterations):\n",
        "\n",
        "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
        "        AL, caches = forward_propagation(X, parameters)\n",
        "\n",
        "        # Compute cost.\n",
        "        cost = cost_function(AL, Y)\n",
        "    \n",
        "        # Backward propagation.\n",
        "        grads = backward_propagation(AL, Y, caches)\n",
        "\n",
        "        # Update parameters.\n",
        "        parameters = update_parameters(parameters, grads, learning_rate)\n",
        "                \n",
        "        # Print the cost every 100 training example\n",
        "        if print_cost and i % 100 == 0:\n",
        "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
        "            costs.append(cost)\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9mXjJev1v9V",
        "colab_type": "text"
      },
      "source": [
        "**Run the Model and Assess Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "aY0sB1iNuqUV",
        "colab_type": "code",
        "outputId": "ca04f73d-9149-4f76-9cbb-9b1318aa748c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "parameters = model(train_x, train_y, layers_dims, num_iterations = 1600, print_cost = True)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after iteration 0: 0.939585\n",
            "Cost after iteration 100: 0.634744\n",
            "Cost after iteration 200: 0.559525\n",
            "Cost after iteration 300: 0.513151\n",
            "Cost after iteration 400: 0.465920\n",
            "Cost after iteration 500: 0.621774\n",
            "Cost after iteration 600: 0.283490\n",
            "Cost after iteration 700: 0.174452\n",
            "Cost after iteration 800: 0.148068\n",
            "Cost after iteration 900: 0.476585\n",
            "Cost after iteration 1000: 0.292070\n",
            "Cost after iteration 1100: 0.155653\n",
            "Cost after iteration 1200: 0.098768\n",
            "Cost after iteration 1300: 0.037415\n",
            "Cost after iteration 1400: 0.014525\n",
            "Cost after iteration 1500: 0.010096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "NIrpeyptuqUX",
        "colab_type": "code",
        "outputId": "5ad358a9-2800-4061-cd07-c664009ab463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred_train = predict(train_x, train_y_orig, parameters)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9919678714859439\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSY8_6jKuqUa",
        "colab_type": "code",
        "outputId": "f138e864-1408-4a8a-fd2e-b44c39b825b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred_test = predict(test_x, test_y_orig, parameters)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.554\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ukHzXeNycaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}